{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x26eae10fe90>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x26eae10fd70>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x26eae2b83c0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x26eae2b1c90>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x26eae2a3090>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x26eae2b8040>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He   |   PRON   |   he\n",
      "'s   |   AUX   |   be\n",
      "in   |   ADP   |   in\n",
      "a   |   DET   |   a\n",
      "boy   |   NOUN   |   boy\n",
      "band   |   NOUN   |   band\n",
      "which   |   PRON   |   which\n",
      "does   |   AUX   |   do\n",
      "n't   |   PART   |   not\n",
      "make   |   VERB   |   make\n",
      "much   |   ADJ   |   much\n",
      "sense   |   NOUN   |   sense\n",
      "for   |   ADP   |   for\n",
      "a   |   DET   |   a\n",
      "snake   |   NOUN   |   snake\n",
      ".   |   PUNCT   |   .\n",
      "The   |   DET   |   the\n",
      "efficiency   |   NOUN   |   efficiency\n",
      "with   |   ADP   |   with\n",
      "which   |   PRON   |   which\n",
      "he   |   PRON   |   he\n",
      "paired   |   VERB   |   pair\n",
      "the   |   DET   |   the\n",
      "socks   |   NOUN   |   sock\n",
      "in   |   ADP   |   in\n",
      "the   |   DET   |   the\n",
      "drawer   |   NOUN   |   drawer\n",
      "was   |   AUX   |   be\n",
      "quite   |   ADV   |   quite\n",
      "admirable   |   ADJ   |   admirable\n",
      ".   |   PUNCT   |   .\n",
      "This   |   PRON   |   this\n",
      "is   |   AUX   |   be\n",
      "the   |   DET   |   the\n",
      "last   |   ADJ   |   last\n",
      "random   |   ADJ   |   random\n",
      "sentence   |   NOUN   |   sentence\n",
      "I   |   PRON   |   I\n",
      "will   |   AUX   |   will\n",
      "be   |   AUX   |   be\n",
      "writing   |   VERB   |   write\n",
      "and   |   CCONJ   |   and\n",
      "I   |   PRON   |   I\n",
      "am   |   AUX   |   be\n",
      "going   |   VERB   |   go\n",
      "to   |   PART   |   to\n",
      "stop   |   VERB   |   stop\n",
      "mid   |   NOUN   |   mid\n",
      "-   |   NOUN   |   -\n",
      "sentWe   |   NOUN   |   sentwe\n",
      "will   |   AUX   |   will\n",
      "not   |   PART   |   not\n",
      "allow   |   VERB   |   allow\n",
      "you   |   PRON   |   you\n",
      "to   |   PART   |   to\n",
      "bring   |   VERB   |   bring\n",
      "your   |   PRON   |   your\n",
      "pet   |   NOUN   |   pet\n",
      "armadillo   |   NOUN   |   armadillo\n",
      "along   |   ADP   |   along\n",
      ".   |   PUNCT   |   .\n",
      "Pair   |   VERB   |   pair\n",
      "your   |   PRON   |   your\n",
      "designer   |   NOUN   |   designer\n",
      "cowboy   |   NOUN   |   cowboy\n",
      "hat   |   NOUN   |   hat\n",
      "with   |   ADP   |   with\n",
      "scuba   |   PROPN   |   scuba\n",
      "gear   |   NOUN   |   gear\n",
      "for   |   ADP   |   for\n",
      "a   |   DET   |   a\n",
      "memorable   |   ADJ   |   memorable\n",
      "occasion   |   NOUN   |   occasion\n",
      ".   |   PUNCT   |   .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"He's in a boy band which doesn't make much sense for a snake.The efficiency with which he paired the socks in the drawer was quite admirable.This is the last random sentence I will be writing and I am going to stop mid-sentWe will not allow you to bring your pet armadillo along.Pair your designer cowboy hat with scuba gear for a memorable occasion.\")\n",
    "\n",
    "for i in doc:\n",
    "    print(i,\"  |  \",i.pos_,\"  |  \",i.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc   |   ORG   |   Companies, agencies, institutions, etc.\n",
      "Elon Musk   |   PERSON   |   People, including fictional\n",
      "more than a Trillion $   |   MONEY   |   Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tesla Inc is owned by Elon Musk and it is worth more than a Trillion $\")\n",
    "\n",
    "for i in doc.ents:\n",
    "    print(i.text,\"  |  \",i.label_,\"  |  \",spacy.explain(i.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
